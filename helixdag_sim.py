#!/usr/bin/env python3
"""
helixdag_sim.py

Lightweight simulator for HelixDAG concepts described in the uploaded whitepaper:
- Multi-parent DAG blocks (k parents)
- Cumulative Proof-weight Function (CPF)
- Continuous Micro-Difficulty Adjustment (CMDA)
- Heterogeneous miners and an optional attacker
- Metrics: energy, orphan rate, throughput, attacker success probability

Usage:
    python helixdag_sim.py

Author: Generated by ChatGPT (based on user's Helixmodel whitepaper)
"""

import random
import math
import time
from collections import defaultdict, deque
import networkx as nx
import numpy as np
import matplotlib.pyplot as plt

# ---------------------
# Parameters / config
# ---------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)

SIM_TIME = 2000               # total simulation time (time units)
TARGET_INTERVAL = 5.0         # target inter-block interval (time units)
ALPHA = 0.25                  # CMDA adaptation coefficient
DEFAULT_K = 3                 # average parents per block (k)
BASE_DIFFICULTY = 1.0         # baseline difficulty unit -> relates to expected work/time
HASH_EFFICIENCY_FACTOR = 2.0  # 'c' from paper: relative efficiency (e.g., BLAKE2b vs SHA-256)
PARALLELISM_FACTOR = 4.0      # p from paper (used for energy estimate)
ENERGY_PER_HASH = 1e-9        # Joules per hash (arbitrary scaling)
BLOCK_PROP_DELAY = 1.0        # average propagation delay (affects orphaning)

# Miner definitions: (id, fraction_of_total_hashrate)
MINERS = [
    ("A", 0.50),  # honest majority p2p miners (50%)
    ("B", 0.30),
    ("C", 0.15),
]
ATTACKER = ("X", 0.05)  # attacker hashrate fraction (can be 0 to simulate no attacker)

# Choose whether to include attacker
INCLUDE_ATTACKER = True

# ---------------------
# Data classes
# ---------------------
class Block:
    def __init__(self, id_, parents, miner_id, difficulty, timestamp, pow_value):
        self.id = id_
        self.parents = list(parents)
        self.miner = miner_id
        self.difficulty = difficulty
        self.timestamp = timestamp
        self.pow_value = pow_value  # raw work metric (e.g., difficulty units)
        self.cum_weight = None  # computed after insertion
        self.confirmed = False

    def __repr__(self):
        return f"Block({self.id}, miner={self.miner}, diff={self.difficulty:.3f}, w={self.cum_weight})"

# ---------------------
# HelixDAG core
# ---------------------
class HelixDAG:
    def __init__(self, target_interval=TARGET_INTERVAL, alpha=ALPHA, k=DEFAULT_K):
        self.G = nx.DiGraph()   # blocks graph (edges parent -> child)
        self.blocks = {}        # id -> Block
        self.tip_set = set()    # block ids considered as tips
        self.next_id = 0
        self.target_interval = target_interval
        self.alpha = alpha
        self.k = k
        # statistics
        self.total_hashes = 0.0
        self.total_energy = 0.0
        self.orphaned_blocks = set()
        self.finalized_weights = {}  # for analysis

        # genesis
        genesis = self._make_block(parents=[], miner_id="genesis", difficulty=BASE_DIFFICULTY, timestamp=0.0, pow_value=BASE_DIFFICULTY)
        genesis.cum_weight = BASE_DIFFICULTY
        self._insert_block(genesis)

    def _make_block(self, parents, miner_id, difficulty, timestamp, pow_value):
        bid = f"B{self.next_id}"
        self.next_id += 1
        return Block(bid, parents, miner_id, difficulty, timestamp, pow_value)

    def _insert_block(self, block: Block):
        # insert into graph
        self.blocks[block.id] = block
        if len(block.parents) == 0:
            self.G.add_node(block.id)
        else:
            for p in block.parents:
                self.G.add_edge(p, block.id)
        # update tipset: new block is a tip, parents may not be tips anymore
        self.tip_set.add(block.id)
        for p in block.parents:
            self.tip_set.discard(p)
        # update cumulative weight (CPF)
        parent_weights = [self.blocks[p].cum_weight for p in block.parents] if block.parents else [0.0]
        block.cum_weight = self._cpf(block.pow_value, parent_weights)
        self.finalized_weights[block.id] = block.cum_weight

    @staticmethod
    def _cpf(pow_value, parent_weights):
        # simple monotonic CPF: pow_value + max(parent_weights)
        # ensures w_i > max(w_p)
        if parent_weights:
            return pow_value + max(parent_weights)
        else:
            return pow_value

    def choose_parents(self, k_override=None):
        k = k_override or self.k
        # choose k parents from tip_set preferentially by cum_weight (higher weight more likely)
        tips = list(self.tip_set)
        if not tips:
            return []
        weights = np.array([self.blocks[t].cum_weight for t in tips], dtype=float)
        # avoid zero-weights; add small epsilon
        weights += 1e-9
        probs = weights / weights.sum()
        chosen = list(np.random.choice(tips, size=min(k, len(tips)), replace=False, p=probs))
        return chosen

    def mine_block(self, miner_id, difficulty, timestamp):
        parents = self.choose_parents()
        # pow_value is modeled proportional to difficulty (raw work)
        pow_value = difficulty
        block = self._make_block(parents=parents, miner_id=miner_id, difficulty=difficulty, timestamp=timestamp, pow_value=pow_value)
        self._insert_block(block)
        return block

    def estimate_orphan_rate(self):
        # crude orphan estimate: fraction of blocks with no children after some propagation window
        orphan_count = sum(1 for b in self.blocks.values() if self.G.out_degree(b.id) == 0 and b.id != "B0")
        total = max(1, len(self.blocks))
        return orphan_count / total

# ---------------------
# Miner model & CMDA
# ---------------------
class Miner:
    def __init__(self, miner_id, hashrate_frac, dag: HelixDAG):
        self.id = miner_id
        self.hashrate_frac = hashrate_frac
        self.dag = dag
        self.local_difficulty = BASE_DIFFICULTY
        # local observed inter-block interval estimator (simple EWMA)
        self.ewma_interval = dag.target_interval

    def attempt_mine(self, global_time, time_step, p_hash_rate):
        """Return mined block or None. We model mining as Poisson process with rate proportional to (hashrate / difficulty)."""
        # effective mining rate = hashrate_frac * p_hash_rate / local_difficulty
        rate = self.hashrate_frac * p_hash_rate / self.local_difficulty
        # The probability to find at least one block in this timestep:
        prob = 1.0 - math.exp(-rate * time_step)
        if random.random() < prob:
            # mined
            block = self.dag.mine_block(self.id, difficulty=self.local_difficulty, timestamp=global_time)
            # update local EWMA and adjust difficulty via CMDA
            observed_interval = time_step  # coarse; could be refined
            self.ewma_interval = (1 - self.dag.alpha) * self.ewma_interval + self.dag.alpha * observed_interval
            self.local_difficulty = max(0.1, self.local_difficulty + self.dag.alpha * (self.dag.target_interval - self.ewma_interval))
            return block
        else:
            return None

# ---------------------
# Simulator
# ---------------------
class Simulator:
    def __init__(self, sim_time=SIM_TIME, time_step=1.0, include_attacker=INCLUDE_ATTACKER):
        self.sim_time = sim_time
        self.time_step = time_step
        self.dag = HelixDAG()
        # total network hashing "power" scaling; controls expected block rates (higher => more blocks)
        self.p_hash_rate = 0.3  # scaling constant
        self.miners = []
        for mid, frac in MINERS:
            self.miners.append(Miner(mid, frac, self.dag))
        if include_attacker:
            self.miners.append(Miner(ATTACKER[0], ATTACKER[1], self.dag))
        # stats
        self.blocks_mined = []
        self.honest_blocks = set()
        self.attacker_blocks = set()
        self.hashes_consumed = 0.0

    def run(self):
        t = 0.0
        last_block_times = defaultdict(lambda: -1.0)
        while t < self.sim_time:
            # each time-step, each miner may find a block
            for miner in self.miners:
                b = miner.attempt_mine(global_time=t, time_step=self.time_step, p_hash_rate=self.p_hash_rate)
                # simulate cost: assume expected number of hashes = difficulty * some constant
                self.hashes_consumed += (miner.hashrate_frac * self.p_hash_rate * self.time_step)
                if b:
                    self.blocks_mined.append(b)
                    if miner.id == ATTACKER[0]:
                        self.attacker_blocks.add(b.id)
                    else:
                        self.honest_blocks.add(b.id)
                    last_block_times[miner.id] = t
            # small random propagation effect: sometimes connect a tip to additional parents to emulate late arrivals
            # with probability proportional to propagation delay variance
            if random.random() < 0.05:
                # pick a random tip and force it to connect to one more parent if available
                tips = list(self.dag.tip_set)
                if len(tips) >= 2:
                    chosen_tip = random.choice(tips)
                    available_parents = [tid for tid in tips if tid != chosen_tip]
                    if available_parents:
                        new_parent = random.choice(available_parents)
                        # rewire by adding an edge new_parent -> chosen_tip (i.e., treat as extra parent)
                        if not self.dag.G.has_edge(new_parent, chosen_tip):
                            self.dag.G.add_edge(new_parent, chosen_tip)
                            # update the cum_weight upward
                            block = self.dag.blocks[chosen_tip]
                            block.cum_weight = self.dag._cpf(block.pow_value, [self.dag.blocks[p].cum_weight for p in block.parents] + [self.dag.blocks[new_parent].cum_weight])
            t += self.time_step
        # compute energy
        energy = self.hashes_consumed * ENERGY_PER_HASH / HASH_EFFICIENCY_FACTOR
        self.dag.total_hashes = self.hashes_consumed
        self.dag.total_energy = energy
        return self._collect_stats()

    def _collect_stats(self):
        total_blocks = len(self.dag.blocks)
        orphan_rate = self.dag.estimate_orphan_rate()
        throughput = total_blocks / (self.sim_time / self.time_step)  # blocks per step
        # attacker success crude metric: fraction of chain weight dominated by attacker
        total_weight = sum(b.cum_weight for b in self.dag.blocks.values())
        attacker_weight = sum(self.dag.blocks[b].cum_weight for b in self.attacker_blocks if b in self.dag.blocks)
        attacker_share = attacker_weight / (total_weight + 1e-12)
        metrics = {
            "total_blocks": total_blocks,
            "blocks_mined": len(self.blocks_mined),
            "orphan_rate": orphan_rate,
            "throughput": throughput,
            "energy_joules": self.dag.total_energy,
            "hashes": self.hashes_consumed,
            "attacker_weight_share": attacker_share,
        }
        return metrics

# ---------------------
# Utilities & plotting
# ---------------------
def plot_basic_metrics(metrics_list, labels):
    # metrics_list: list of metrics dicts
    orphans = [m["orphan_rate"] for m in metrics_list]
    energy = [m["energy_joules"] for m in metrics_list]
    throughput = [m["throughput"] for m in metrics_list]
    attacker_share = [m["attacker_weight_share"] for m in metrics_list]

    x = np.arange(len(metrics_list))
    plt.figure(figsize=(12, 8))
    plt.subplot(2, 2, 1)
    plt.plot(x, orphans, marker='o')
    plt.title("Orphan Rate")
    plt.xticks(x, labels)

    plt.subplot(2, 2, 2)
    plt.plot(x, energy, marker='o')
    plt.title("Energy (Joules)")
    plt.xticks(x, labels)

    plt.subplot(2, 2, 3)
    plt.plot(x, throughput, marker='o')
    plt.title("Throughput (blocks / step)")
    plt.xticks(x, labels)

    plt.subplot(2, 2, 4)
    plt.plot(x, attacker_share, marker='o')
    plt.title("Attacker Weight Share")
    plt.xticks(x, labels)

    plt.tight_layout()
    plt.savefig("helixdag_metrics.png")
    print("Saved metrics plot to helixdag_metrics.png")
    plt.show()

def dump_graph(dag: HelixDAG, filename="helixdag_graph.gml"):
    nx.write_gml(dag.G, filename)
    print(f"Wrote DAG graph to {filename} (GML)")

# ---------------------
# Main: run a few experiments
# ---------------------
def main():
    print("HelixDAG Simulator â€” starting experiments")
    # baseline: with attacker and default params
    sim1 = Simulator(sim_time=SIM_TIME, time_step=1.0, include_attacker=INCLUDE_ATTACKER)
    metrics1 = sim1.run()
    print("Run 1 metrics:", metrics1)

    # experiment: increase parallelism effect (simulate larger k by giving DAG more parent choices)
    sim2 = Simulator(sim_time=SIM_TIME, time_step=1.0, include_attacker=INCLUDE_ATTACKER)
    sim2.dag.k = 5
    metrics2 = sim2.run()
    print("Run 2 (k=5) metrics:", metrics2)

    # experiment: no attacker
    sim3 = Simulator(sim_time=SIM_TIME, time_step=1.0, include_attacker=False)
    metrics3 = sim3.run()
    print("Run 3 (no attacker) metrics:", metrics3)

    metrics_list = [metrics1, metrics2, metrics3]
    labels = ["base", "k=5", "no_attacker"]
    plot_basic_metrics(metrics_list, labels)

    # export graph for further inspection (from last sim)
    dump_graph(sim3.dag, filename="helixdag_no_attacker.gml")

    # print short summary matching claims in the whitepaper
    # compute effective energy ratio compared to a hypothetical linear chain:
    E_linear = metrics3["energy_joules"] * PARALLELISM_FACTOR  # simplified mapping
    effective_reduction = E_linear / metrics3["energy_joules"]
    print(f"Estimated effective energy reduction factor (rough): {effective_reduction:.2f}x")

if __name__ == "__main__":
    main()
